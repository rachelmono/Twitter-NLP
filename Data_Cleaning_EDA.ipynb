{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet data cleaning and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AFTER covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import GetOldTweets3 as got\n",
    "import pandas as pd\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'after.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datetime'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english', max_df=0.50, min_df=2)\n",
    "X = vect.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "X_dense = X.todense()\n",
    "coords = PCA(n_components=3).fit_transform(X_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean')\n",
    "y_pred = cluster.fit_predict(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(coords[:,0],coords[:,1], c=cluster.labels_, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = set([ 'RBR', 'JJ', 'JJR', 'JJS'])\n",
    "res=[]\n",
    "for i in df.Text.apply(lambda x: x.split()):\n",
    "    res.append(nltk.pos_tag(i))\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "ret = []\n",
    "for word,pos in flatten(res):\n",
    "        if (pos in tags):\n",
    "            ret.append(word)\n",
    "ret=[i.strip('#@&') for i in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from subprocess import check_output\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "mpl.rcParams['figure.figsize']=(16.0,10.0)    \n",
    "mpl.rcParams['font.size']=12                \n",
    "mpl.rcParams['savefig.dpi']=1400             \n",
    "mpl.rcParams['figure.subplot.bottom']=.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "l=['big','due', 'sure', 'able','home.', 'much','amp;','first', 'last', ', next', 'little', 'many', 'new','work from home','covid_19uk','cowvid19','-','.','remoteworking','wfh','','covid-19','covid','workfromhome','remote','remotely', 'workremotely','workingfromhome', 'covid19','coronavirus','remotEworking','covid_19','COVID19','Covid_19','COVID','working home', 'WFH', 'work','home', 'office', 'working', 'remotework','work from home', 'workfromhome', 'workingfromhome','workremotely','remote','remotely', 'COVID 19','coronavirus','remotEworking','COVID__19','COVID19','Covid_19','COVID','working home', 'WFH', 'work','home', 'office', 'working', 'remotework']\n",
    "for i in l:\n",
    "    stopwords.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_mask = np.array(Image.open('twitter_mask.png'))\n",
    "text = \" \".join(tweet for tweet in ret)\n",
    "print (\"There are {} words in the combination of all tweets.\".format(len(text)))\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stopwords,\n",
    "                          max_words=35,\n",
    "                          max_font_size=150, \n",
    "                          random_state=42,\n",
    "                          mask = pos_mask,\n",
    "                          contour_width=1,\n",
    "                          colormap=\"spring\",\n",
    "                          contour_color='black'\n",
    "\n",
    "                         ).generate(str(text))\n",
    "\n",
    "print(wordcloud)\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before COVID19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv('before.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.drop_duplicates().reset_index(drop=True)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = set(['JJ', 'JJR', 'JJS'])\n",
    "res=[]\n",
    "for i in df2.Text.apply(lambda x: x.split()):\n",
    "    res.append(nltk.pos_tag(i))\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "ret = []\n",
    "for word,pos in flatten(res):\n",
    "        if (pos in tags):\n",
    "            ret.append(word)\n",
    "ret=[i.strip('#@&') for i in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize']=(14.0,10.0)    \n",
    "mpl.rcParams['font.size']=12                \n",
    "mpl.rcParams['savefig.dpi']=140             \n",
    "mpl.rcParams['figure.subplot.bottom']=.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "l=['big','due', 'sure', 'able','home.', 'much','amp;','first', 'last', ', next', 'little', 'many', 'new','work from home','covid_19uk','cowvid19','-','.','remoteworking','wfh','','covid-19','covid','workfromhome','remote','remotely', 'workremotely','workingfromhome', 'covid19','coronavirus','remotEworking','covid_19','COVID19','Covid_19','COVID','working home', 'WFH', 'work','home', 'office', 'working', 'remotework','work from home', 'workfromhome', 'workingfromhome','remote','remotely', 'COVID 19','coronavirus','remotEworking','COVID__19','COVID19','Covid_19','COVID','working home', 'WFH', 'work','home', 'office', 'working', 'remotework']\n",
    "for i in l:\n",
    "    stopwords.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_mask = np.array(Image.open('twitter_mask.png'))\n",
    "text = \" \".join(tweet for tweet in ret)\n",
    "print (\"There are {} words in the combination of all tweets.\".format(len(text)))\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stopwords,\n",
    "                          max_words=35,\n",
    "                          max_font_size=150, \n",
    "                          random_state=42,\n",
    "                          mask = pos_mask,\n",
    "                          contour_width=1,\n",
    "                          colormap=\"spring\",\n",
    "                          contour_color='black'\n",
    "\n",
    "                         ).generate(str(text))\n",
    "\n",
    "print(wordcloud)\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# fig.savefig(\"word1.png\", dpi=1400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from 2019-07-2020-09-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "df=pd.read_csv(r'tweets.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by='Datetime').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Text=df.Text.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=['remote', 'hr', 'HR' ,'WFH','job','career' 'work', 'Job', 'remotely', 'covid', 'offer', 'Work','law', 'Trainee', 'employ','market','Manage','web', 'Web', 'covid', 'COVID', 'health', 'coronavirus', 'Team', 'team']\n",
    "a=[]\n",
    "for i in df['Tweet User']:\n",
    "    for j in lst:\n",
    "        if j in i:\n",
    "            a.append(i)\n",
    "df=df[~df['Tweet User'].isin(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].drop_duplicates()\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst2=['http', 'tip', 'opportunity', 'hir','career', 'offer','subscribe', 'hr', 'follow', 'survey', 'employ']\n",
    "b=[]\n",
    "for i in df['Text']:\n",
    "    for j in lst2:\n",
    "        if j in i:\n",
    "            b.append(i)\n",
    "df=df[~df['Text'].isin(b)].reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. words cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = set([ 'JJ', 'JJR', 'JJS'])\n",
    "res=[]\n",
    "for i in df.Text.apply(lambda x: x.split()):\n",
    "    res.append(nltk.pos_tag(i))\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "ret = []\n",
    "for word,pos in flatten(res):\n",
    "        if (pos in tags):\n",
    "            ret.append(word)\n",
    "ret=[i.strip('#@&') for i in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from subprocess import check_output\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "mpl.rcParams['figure.figsize']=(16.0,10.0)    \n",
    "mpl.rcParams['font.size']=12                \n",
    "mpl.rcParams['savefig.dpi']=1400             \n",
    "mpl.rcParams['figure.subplot.bottom']=.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "l=['work from home', 'workfromhome','remote','remotely', 'workremotely','workingfromhome', 'COVID 19','coronavirus','remotEworking','COVID__19','COVID19','Covid_19','COVID','working home', 'WFH', 'work','home', 'office', 'working', 'remotework']\n",
    "for i in l:\n",
    "    stopwords.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_mask = np.array(Image.open('twitter_mask.png'))\n",
    "text = \" \".join(tweet for tweet in ret)\n",
    "print (\"There are {} words in the combination of all tweets.\".format(len(text)))\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stopwords,\n",
    "                          max_words=35,\n",
    "                          max_font_size=150, \n",
    "                          random_state=42,\n",
    "                          mask = pos_mask,\n",
    "                          contour_width=1,\n",
    "                          colormap=\"winter\",\n",
    "                          contour_color='black'\n",
    "\n",
    "                         ).generate(str(text))\n",
    "\n",
    "print(wordcloud)\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# fig.savefig(\"word1.png\", dpi=1400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Calculate and Plot Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret=[i.lower() for i in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import tweepy as tw\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Remove Stopwords With nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "# View a few words from the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "text_new= [word for word in ret if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(text_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove collection words:\n",
    "collection_words =['big','due', 'sure', 'able','home.', 'much','amp;','first', 'last', ', next', 'little', 'many', 'new','work from home','covid_19uk','cowvid19','-','.','remoteworking','wfh','','covid-19','covid','workfromhome','remote','remotely', 'workremotely','workingfromhome', 'covid19','coronavirus','remotEworking','covid_19','COVID19','Covid_19','COVID','working home', 'WFH', 'work','home', 'office', 'working', 'remotework']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_no_coll= [word for word in text_new if word not in collection_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(text_no_coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Create counter\n",
    "text_count=Counter(text_no_coll).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(text_count,columns=['words', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot horizontal bar graph\n",
    "text_df.sort_values(by='count', ascending=False)[:20].plot.barh(x='words',\n",
    "                      y='count',\n",
    "                      ax=ax,\n",
    "                      color=\"pink\")\n",
    "ax.set_title(\"Common Words about Remotework Tweets\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.treemap(text_df.sort_values(by='count', ascending=False)[:30], path=['words'], values='count',title='Tree of Most Common Words')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Co-occurring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.sort_values(by='count', ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove collection words:\n",
    "collection_words =['work from home','covid_19uk','cowvid_19','workingfromhomelife','cowvid19','-','.','remoteworking','wfh','','covid-19','covid','workfromhome','remote','remotely', 'workremotely','workingfromhome', 'covid19','coronavirus','remotEworking','covid_19','COVID19','Covid_19','COVID','working home', 'WFH', 'work','home', 'office', 'working', 'remotework']\n",
    "text_no_coll= [word for word in text_new if word not in collection_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx as nx\n",
    "bigram=list(bigrams(text_no_coll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = Counter(bigram)\n",
    "\n",
    "bigram_counts.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df = pd.DataFrame(bigram_counts.most_common(30),\n",
    "                             columns=['bigram', 'count'])\n",
    "\n",
    "bigram_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Networks of Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of bigrams and their counts\n",
    "d = bigram_df.set_index('bigram').T.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network plot \n",
    "G = nx.Graph()\n",
    "\n",
    "# Create connections between nodes\n",
    "for k, v in d[0].items():\n",
    "    G.add_edge(k[0], k[1], weight=(v * 10))\n",
    "\n",
    "G.add_node(\"china\", weight=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "pos = nx.spring_layout(G, k=2)\n",
    "\n",
    "# Plot networks\n",
    "nx.draw_networkx(G, pos,\n",
    "                 font_size=9,\n",
    "                 width=1,\n",
    "                 edge_color='grey',\n",
    "                 node_color='pink',\n",
    "                 with_labels = False,\n",
    "                 ax=ax)\n",
    "\n",
    "# Create offset labels\n",
    "for key, value in pos.items():\n",
    "    x, y = value[0]+.075, value[1]+.024\n",
    "    ax.text(x, y,\n",
    "            s=key,\n",
    "            bbox=dict(facecolor='pink', alpha=0.25),\n",
    "            horizontalalignment='center', fontsize=16)\n",
    "plt.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Sentiments in Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "# Create textblob objects of the tweets\n",
    "text_analysis = [TextBlob(tweet) for tweet in df.Text]\n",
    "text_analysis[0].polarity, text_analysis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create list of polarity valuesx and tweet text\n",
    "text_values = [[tweet.sentiment.polarity, str(tweet)] for tweet in text_analysis]\n",
    "text_values[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe containing the polarity value and tweet text\n",
    "sentiment_df = pd.DataFrame(text_values, columns=[\"polarity\", \"tweet\"])\n",
    "sentiment_df['polarity']=sentiment_df.polarity.round(3)\n",
    "\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot histogram of the polarity values\n",
    "sentiment_df.hist(bins=[-1, -0.75, -0.5, -0.25, 0.25, 0.5, 0.75, 1],\n",
    "             ax=ax,\n",
    "             color=\"pink\")\n",
    "\n",
    "plt.title(\"Sentiments from Tweets on remote work\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove polarity values equal to zero\n",
    "sentiment_df = sentiment_df[sentiment_df.polarity != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot histogram with break at zero\n",
    "sentiment_df.hist(bins=[-1, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1],\n",
    "             ax=ax,\n",
    "             color=\"pink\")\n",
    "\n",
    "plt.title(\"Sentiments from Tweets on Remote work\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['time']=df['Datetime']\n",
    "sentiment_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "sentiment_df['time']=pd.to_datetime(sentiment_df['time'], utc=True).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polarity=sentiment_df.groupby('time')['polarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[]\n",
    "for i in range(len(df_polarity)):\n",
    "    p.append(df_polarity[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time=sentiment_df['time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity=pd.DataFrame(time, columns=['time'])\n",
    "polarity['polarity']=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in polarity['time']:\n",
    "    t=0\n",
    "    if i > dt.date(2020, 3, 15) :\n",
    "        t=1\n",
    "    else: \n",
    "        t=0\n",
    "    a.append(t)\n",
    "polarity['period']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(polarity.time - dayZero).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bit of munging - better column name - Day as integer \n",
    "dayZero = polarity.time[0]\n",
    "polarity['Day'] = (polarity.time - dayZero).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit a linear regression\n",
    "import statsmodels.formula.api as sm\n",
    "fit = sm.ols(formula=\"polarity ~ Day\", data=polarity).fit()\n",
    "print(fit.summary())\n",
    "predict = fit.predict(polarity)\n",
    "polarity['fitted'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.scatter('time', 'p', c='period', data=polarity)\n",
    "ax.plot(polarity.time, polarity.fitted, 'r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datapungi_fed as dpf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-poster')\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_ts=polarity.set_index(pd.DatetimeIndex(polarity['time']), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts=p_ts.drop(columns=['time', 'period'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 4))\n",
    "sns.lineplot(data = ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the series\n",
    "p_week = ts.resample('W').last()\n",
    "p_month = ts.resample('M').last()\n",
    "p_q = ts.resample('Q').last()\n",
    "p_year = ts.resample('A').last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_week=p_week.fillna(method='bfill')\n",
    "p_month=p_month.fillna(method='bfill')\n",
    "p_q=p_q.fillna(method='bfill')\n",
    "p_year=p_year.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 8))\n",
    "plt.subplot(221)\n",
    "plt.title('Weekly')\n",
    "sns.lineplot(data = p_week)\n",
    "plt.subplot(222)\n",
    "plt.title('Quartly')\n",
    "sns.lineplot(data = p_q)\n",
    "plt.subplot(223)\n",
    "plt.title('Monthly')\n",
    "sns.lineplot(data = p_month)\n",
    "plt.subplot(224)\n",
    "plt.title('Annual')\n",
    "sns.lineplot(data = p_year)\n",
    "plt.xticks()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can see after the transformation, the series has an upward trend. It shows people are getting more and more statisfied with remotely work. We run the Dickey–Fuller test to verify the stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# first difference\n",
    "diff1 = dta = p_week.diff(1)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sm.tsa.stattools.adfuller(p_week.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is smaller 0.05, and the adf results are smaller than different level value(expect 1%), so we refuse hypothesis, so this data are stationary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Dickey–Fuller test for weekly: p=%f\" %sm.tsa.stattools.adfuller(p_week.polarity)[1])\n",
    "print(\"Dickey–Fuller test for monthly: p=%f\" %sm.tsa.stattools.adfuller(p_month.polarity)[1])\n",
    "print(\"Dickey–Fuller test for quartly: p=%f\" %sm.tsa.stattools.adfuller(p_q.polarity)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=sm.tsa.statespace.SARIMAX(ts, order=(1,1,1),\n",
    "                             seasonal_order=(1,1,1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m=mod.fit()\n",
    "print(m.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_diagnostics(figsize=(10,8))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m.get_prediction(dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax=ts.plot(label='observed',figsize=(12,5))\n",
    "pred.predicted_mean.plot(ax=ax, label='prediction', alpha=.6)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the data to the requirement of the prophet requirement, ds for datetime and y for price index\n",
    "ts = ts.reset_index()\n",
    "ts.columns = ['ds', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts['ds'].min(), ts['ds'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initiate a prophet object to fit the data\n",
    "m = Prophet()\n",
    "m.fit(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a future prediction the next month\n",
    "future = m.make_future_dataframe(periods = 60)\n",
    "future.tail() # note that the original data set only has 1941 rows, 30 new rows have been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from fbprophet.plot import add_changepoints_to_plot\n",
    "fig1 = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_month = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_month['ds'] = pd.to_datetime(next_month['ds'])\n",
    "next_month = next_month.set_index('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = m.plot_components(forecast)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
